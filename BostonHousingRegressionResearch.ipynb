{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston housing dataset has 489 data points with 4 variables each.\n",
      "0    504000.0\n",
      "1    453600.0\n",
      "2    728700.0\n",
      "3    701400.0\n",
      "4    760200.0\n",
      "Name: MEDV, dtype: float64\n",
      "      RM  LSTAT  PTRATIO\n",
      "0  6.575   4.98     15.3\n",
      "1  6.421   9.14     17.8\n",
      "2  7.185   4.03     17.8\n",
      "3  6.998   2.94     18.7\n",
      "4  7.147   5.33     18.7\n"
     ]
    }
   ],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "\n",
    "# Import supplementary visualizations code visuals.py\n",
    "import visuals as vs\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the Boston housing dataset\n",
    "data = pd.read_csv('housing.csv')\n",
    "prices = data['MEDV']\n",
    "features = data.drop('MEDV', axis = 1)\n",
    "    \n",
    "# Success\n",
    "print(\"Boston housing dataset has {} data points with {} variables each.\".format(*data.shape))\n",
    "print(prices.head())\n",
    "print(features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import 'r2_score'\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def performance_metric(y_true, y_predict):\n",
    "    \"\"\" Calculates and returns the performance score between \n",
    "        true and predicted values based on the metric chosen. \"\"\"\n",
    "    \n",
    "    # TODO: Calculate the performance score between 'y_true' and 'y_predict'\n",
    "    score = r2_score(y_true, y_predict) \n",
    "    \n",
    "    # Return the score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has a coefficient of determination, R^2, of 0.923.\n"
     ]
    }
   ],
   "source": [
    "# Calculate the performance of this model\n",
    "score = performance_metric([3, -0.5, 2, 7, 4.2], [2.5, 0.0, 2.1, 7.8, 5.3])\n",
    "print(\"Model has a coefficient of determination, R^2, of {:.3f}.\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing split was successful.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Import 'train_test_split'\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TODO: Shuffle and split the data into training and testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, prices, test_size=0.2, random_state=42)\n",
    "\n",
    "# Success\n",
    "print(\"Training and testing split was successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My using of Linear Regression on the boston housing price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted selling price for Client 1's home: $374,221.68\n",
      "Predicted selling price for Client 2's home: $-7,680.95\n",
      "Predicted selling price for Client 3's home: $842,850.45\n",
      "Model has a coefficient of determination, R^2, of 0.691.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "client_data = [[5, 17, 15], # Client 1\n",
    "               [4, 32, 22], # Client 2\n",
    "               [8, 3, 12]]  # Client 3\n",
    "\n",
    "# Show predictions\n",
    "for i, price in enumerate(model.predict(client_data)):\n",
    "    print(\"Predicted selling price for Client {}'s home: ${:,.2f}\".format(i+1, price))\n",
    "    \n",
    "    \n",
    "# Calculate the performance of this model\n",
    "score = performance_metric(y_test, model.predict(X_test))\n",
    "print(\"Model has a coefficient of determination, R^2, of {:.3f}.\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My using of Decision Tree Regression on boston housing price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted selling price for Client 1's home: $403,025.00\n",
      "Predicted selling price for Client 2's home: $237,478.72\n",
      "Predicted selling price for Client 3's home: $931,636.36\n",
      "Model has a coefficient of determination, R^2, of 0.844.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Import 'make_scorer', 'DecisionTreeRegressor', and 'GridSearchCV'\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "model = DecisionTreeRegressor(max_depth = 4)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "client_data = [[5, 17, 15], # Client 1\n",
    "               [4, 32, 22], # Client 2\n",
    "               [8, 3, 12]]  # Client 3\n",
    "\n",
    "# Show predictions\n",
    "for i, price in enumerate(model.predict(client_data)):\n",
    "    print(\"Predicted selling price for Client {}'s home: ${:,.2f}\".format(i+1, price))\n",
    "    \n",
    "    \n",
    "# Calculate the performance of this model\n",
    "score = performance_metric(y_test, model.predict(X_test))\n",
    "print(\"Model has a coefficient of determination, R^2, of {:.3f}.\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my use of MLP Regressor on boston housing price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted selling price for Client 1's home: $1,440.91\n",
      "Predicted selling price for Client 2's home: $2,228.92\n",
      "Predicted selling price for Client 3's home: $923.82\n",
      "Model has a coefficient of determination, R^2, of -8.154.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "model = MLPRegressor(activation= 'identity')\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "client_data = [[5, 17, 15], # Client 1\n",
    "               [4, 32, 22], # Client 2\n",
    "               [8, 3, 12]]  # Client 3\n",
    "\n",
    "# Show predictions\n",
    "for i, price in enumerate(model.predict(client_data)):\n",
    "    print(\"Predicted selling price for Client {}'s home: ${:,.2f}\".format(i+1, price))\n",
    "    \n",
    "    \n",
    "# Calculate the performance of this model\n",
    "score = performance_metric(y_test, model.predict(X_test))\n",
    "print(\"Model has a coefficient of determination, R^2, of {:.3f}.\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# my use of svr on boston housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted selling price for Client 1's home: $350,537.05\n",
      "Predicted selling price for Client 2's home: $345,455.44\n",
      "Predicted selling price for Client 3's home: $934,971.97\n",
      "Model has a coefficient of determination, R^2, of 0.803.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "#model = SVR(C=1.0, epsilon=0.2)\n",
    "model = SVR(C=10, degree=3, epsilon=0.1, gamma='auto', kernel='poly')\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "client_data = [[5, 17, 15], # Client 1\n",
    "               [4, 32, 22], # Client 2\n",
    "               [8, 3, 12]]  # Client 3\n",
    "\n",
    "# Show predictions\n",
    "for i, price in enumerate(model.predict(client_data)):\n",
    "    print(\"Predicted selling price for Client {}'s home: ${:,.2f}\".format(i+1, price))\n",
    "    \n",
    "    \n",
    "# Calculate the performance of this model\n",
    "score = performance_metric(y_test, model.predict(X_test))\n",
    "print(\"Model has a coefficient of determination, R^2, of {:.3f}.\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The R2 score is the proportion of the variance in the dependent variable that is predictable from the independent variable. In other words:\n",
    "* R2 score of 0 means that the dependent variable cannot be predicted from the independent variable.\n",
    "* R2 score of 1 means the dependent variable can be predicted from the independent variable.\n",
    "* R2 score between 0 and 1 indicates the extent to which the dependent variable is predictable.\n",
    "* R2 score of 0.40 means that 40 percent of the variance in Y is predictable from X.\n",
    "\n",
    "* The values for R2 range from 0 to 1, which captures the percentage of squared correlation between the predicted and actual values of the target variable. A model with an R2 of 0 is no better than a model that always predicts the mean of the target variable, whereas a model with an R2 of 1 perfectly predicts the target variable. Any value between 0 and 1 indicates what percentage of the target variable, using this model, can be explained by the features. A model can be given a negative R2 as well, which indicates that the model is arbitrarily worse than one that always predicts the mean of the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search on each algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter is {'criterion': 'mse', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': False, 'random_state': None, 'splitter': 'best'} for the optimal model.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#parameters = {'kernel':['poly', 'rbf'],'C':[0.1, 1, 10]}\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "#scorer = make_scorer(f1_score)\n",
    "\n",
    "# TODO: Create a decision tree regressor object\n",
    "regressor = DecisionTreeRegressor()\n",
    "\n",
    "# TODO: Create a dictionary for the parameter 'max_depth' with a range from 1 to 10\n",
    "params = {'max_depth': list(range(1,11))}\n",
    "\n",
    "\n",
    "# Create cross-validation sets from the training data\n",
    "# sklearn version 0.18: ShuffleSplit(n_splits=10, test_size=0.1, train_size=None, random_state=None)\n",
    "# sklearn versiin 0.17: ShuffleSplit(n, n_iter=10, test_size=0.1, train_size=None, random_state=None)\n",
    "cv_sets = ShuffleSplit(X_train.shape[0], n_iter = 10, test_size = 0.20, random_state = 0)\n",
    "\n",
    "# TODO: Transform 'performance_metric' into a scoring function using 'make_scorer' \n",
    "scoring_fnc = make_scorer(performance_metric)\n",
    "\n",
    "# Create the object.\n",
    "#grid_obj = GridSearchCV(regressor, parameters, scoring=scorer)\n",
    "# TODO: Create the grid search cv object --> GridSearchCV()\n",
    "# Make sure to include the right parameters in the object:\n",
    "# (estimator, param_grid, scoring, cv) which have values 'regressor', 'params', 'scoring_fnc', and 'cv_sets' respectively.\n",
    "grid = GridSearchCV(regressor, params, scoring = scoring_fnc, cv = cv_sets)\n",
    "\n",
    "# Fit the data\n",
    "grid_fit = grid.fit(X_train, y_train)\n",
    "\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "# Produce the value for 'max_depth'\n",
    "#print(\"Parameter 'max_depth' is {} for the optimal model.\".format(best_clf.get_params()['max_depth']))\n",
    "print(\"Parameter is {} for the optimal model.\".format(best_clf.get_params()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C : float, optional (default=1.0)\n",
    "Penalty parameter C of the error term.\n",
    "epsilon : float, optional (default=0.1)\n",
    "Epsilon in the epsilon-SVR model. It specifies the epsilon-tube within which no penalty is associated in the training loss function with points predicted within a distance epsilon from the actual value.\n",
    "kernel : string, optional (default=’rbf’)\n",
    "Specifies the kernel type to be used in the algorithm. It must be one of ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ or a callable. If none is given, ‘rbf’ will be used. If a callable is given it is used to precompute the kernel matrix.\n",
    "degree : int, optional (default=3)\n",
    "Degree of the polynomial kernel function (‘poly’). Ignored by all other kernels.\n",
    "gamma : float, optional (default=’auto’)\n",
    "Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’. If gamma is ‘auto’ then 1/n_features will be used instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# grid search for SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter  is {'C': 10, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'poly', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False} for the optimal model.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#parameters = {'kernel':['poly', 'rbf'],'C':[0.1, 1, 10]}\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "#scorer = make_scorer(f1_score)\n",
    "\n",
    "# TODO: Create a decision tree regressor object\n",
    "regressor = SVR()\n",
    "\n",
    "# TODO: Create a dictionary for the parameter 'max_depth' with a range from 1 to 10\n",
    "#params = {'max_depth': list(range(1,11))}\n",
    "params = {'kernel':['poly', 'rbf'],'C':[0.1, 1, 10]}\n",
    "\n",
    "# Create cross-validation sets from the training data\n",
    "# sklearn version 0.18: ShuffleSplit(n_splits=10, test_size=0.1, train_size=None, random_state=None)\n",
    "# sklearn versiin 0.17: ShuffleSplit(n, n_iter=10, test_size=0.1, train_size=None, random_state=None)\n",
    "cv_sets = ShuffleSplit(X_train.shape[0], n_iter = 10, test_size = 0.20, random_state = 0)\n",
    "\n",
    "# TODO: Transform 'performance_metric' into a scoring function using 'make_scorer' \n",
    "scoring_fnc = make_scorer(performance_metric)\n",
    "\n",
    "# Create the object.\n",
    "#grid_obj = GridSearchCV(regressor, parameters, scoring=scorer)\n",
    "# TODO: Create the grid search cv object --> GridSearchCV()\n",
    "# Make sure to include the right parameters in the object:\n",
    "# (estimator, param_grid, scoring, cv) which have values 'regressor', 'params', 'scoring_fnc', and 'cv_sets' respectively.\n",
    "grid = GridSearchCV(regressor, params, scoring = scoring_fnc, cv = cv_sets)\n",
    "\n",
    "# Fit the data\n",
    "grid_fit = grid.fit(X_train, y_train)\n",
    "\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "# Produce the value for 'max_depth'\n",
    "print(\"Parameter  is {} for the optimal model.\".format(best_clf.get_params()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# grid search for MLPregressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter  is {'activation': 'identity', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_iter': 200, 'momentum': 0.9, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': None, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False} for the optimal model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#parameters = {'kernel':['poly', 'rbf'],'C':[0.1, 1, 10]}\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "#scorer = make_scorer(f1_score)\n",
    "\n",
    "# TODO: Create a decision tree regressor object\n",
    "regressor = MLPRegressor()\n",
    "\n",
    "# TODO: Create a dictionary for the parameter 'max_depth' with a range from 1 to 10\n",
    "#params = {'max_depth': list(range(1,11))}\n",
    "#params = {'kernel':['poly', 'rbf'],'C':[0.1, 1, 10]}\n",
    "params = {'activation':['identity', 'logistic', 'tanh', 'relu']}\n",
    "#          , \n",
    "#          'solver':['lbfgs', 'sgd', 'adam'], 'alpha' : [0.0001, 0.001, 0.01]\n",
    "\n",
    "# Create cross-validation sets from the training data\n",
    "# sklearn version 0.18: ShuffleSplit(n_splits=10, test_size=0.1, train_size=None, random_state=None)\n",
    "# sklearn versiin 0.17: ShuffleSplit(n, n_iter=10, test_size=0.1, train_size=None, random_state=None)\n",
    "cv_sets = ShuffleSplit(X_train.shape[0], n_iter = 10, test_size = 0.20, random_state = 0)\n",
    "\n",
    "# TODO: Transform 'performance_metric' into a scoring function using 'make_scorer' \n",
    "scoring_fnc = make_scorer(performance_metric)\n",
    "\n",
    "# Create the object.\n",
    "#grid_obj = GridSearchCV(regressor, parameters, scoring=scorer)\n",
    "# TODO: Create the grid search cv object --> GridSearchCV()\n",
    "# Make sure to include the right parameters in the object:\n",
    "# (estimator, param_grid, scoring, cv) which have values 'regressor', 'params', 'scoring_fnc', and 'cv_sets' respectively.\n",
    "grid = GridSearchCV(regressor, params, scoring = scoring_fnc, cv = cv_sets)\n",
    "\n",
    "# Fit the data\n",
    "grid_fit = grid.fit(X_train, y_train)\n",
    "\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "# Produce the value for 'max_depth'\n",
    "print(\"Parameter  is {} for the optimal model.\".format(best_clf.get_params()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted selling price for Client 1's home: $320,833.33\n",
      "Predicted selling price for Client 2's home: $238,116.67\n",
      "Predicted selling price for Client 3's home: $881,533.33\n",
      "Model has a coefficient of determination, R^2, of 0.853.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators=18)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "client_data = [[5, 17, 15], # Client 1\n",
    "               [4, 32, 22], # Client 2\n",
    "               [8, 3, 12]]  # Client 3\n",
    "\n",
    "# Show predictions\n",
    "for i, price in enumerate(model.predict(client_data)):\n",
    "    print(\"Predicted selling price for Client {}'s home: ${:,.2f}\".format(i+1, price))\n",
    "    \n",
    "    \n",
    "# Calculate the performance of this model\n",
    "score = performance_metric(y_test, model.predict(X_test))\n",
    "print(\"Model has a coefficient of determination, R^2, of {:.3f}.\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# grid search in Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter  is {'bootstrap': True, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 18, 'n_jobs': 1, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False} for the optimal model.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#parameters = {'kernel':['poly', 'rbf'],'C':[0.1, 1, 10]}\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "#scorer = make_scorer(f1_score)\n",
    "\n",
    "# TODO: Create a decision tree regressor object\n",
    "regressor = RandomForestRegressor()\n",
    "\n",
    "# TODO: Create a dictionary for the parameter 'max_depth' with a range from 1 to 10\n",
    "#params = {'max_depth': list(range(1,11))}\n",
    "#params = {'kernel':['poly', 'rbf'],'C':[0.1, 1, 10]}\n",
    "params = {'n_estimators':list(range(1,20))}\n",
    "#          , \n",
    "#          'solver':['lbfgs', 'sgd', 'adam'], 'alpha' : [0.0001, 0.001, 0.01]\n",
    "\n",
    "# Create cross-validation sets from the training data\n",
    "# sklearn version 0.18: ShuffleSplit(n_splits=10, test_size=0.1, train_size=None, random_state=None)\n",
    "# sklearn versiin 0.17: ShuffleSplit(n, n_iter=10, test_size=0.1, train_size=None, random_state=None)\n",
    "cv_sets = ShuffleSplit(X_train.shape[0], n_iter = 10, test_size = 0.20, random_state = 0)\n",
    "\n",
    "# TODO: Transform 'performance_metric' into a scoring function using 'make_scorer' \n",
    "scoring_fnc = make_scorer(performance_metric)\n",
    "\n",
    "# Create the object.\n",
    "#grid_obj = GridSearchCV(regressor, parameters, scoring=scorer)\n",
    "# TODO: Create the grid search cv object --> GridSearchCV()\n",
    "# Make sure to include the right parameters in the object:\n",
    "# (estimator, param_grid, scoring, cv) which have values 'regressor', 'params', 'scoring_fnc', and 'cv_sets' respectively.\n",
    "grid = GridSearchCV(regressor, params, scoring = scoring_fnc, cv = cv_sets)\n",
    "\n",
    "# Fit the data\n",
    "grid_fit = grid.fit(X_train, y_train)\n",
    "\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "# Produce the value for 'max_depth'\n",
    "print(\"Parameter  is {} for the optimal model.\".format(best_clf.get_params()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted selling price for Client 1's home: $397,558.47\n",
      "Predicted selling price for Client 2's home: $249,029.73\n",
      "Predicted selling price for Client 3's home: $897,031.58\n",
      "Model has a coefficient of determination, R^2, of 0.837.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "model = AdaBoostRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "client_data = [[5, 17, 15], # Client 1\n",
    "               [4, 32, 22], # Client 2\n",
    "               [8, 3, 12]]  # Client 3\n",
    "\n",
    "# Show predictions\n",
    "for i, price in enumerate(model.predict(client_data)):\n",
    "    print(\"Predicted selling price for Client {}'s home: ${:,.2f}\".format(i+1, price))\n",
    "    \n",
    "    \n",
    "# Calculate the performance of this model\n",
    "score = performance_metric(y_test, model.predict(X_test))\n",
    "print(\"Model has a coefficient of determination, R^2, of {:.3f}.\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try Gradient Booster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted selling price for Client 1's home: $315,015.11\n",
      "Predicted selling price for Client 2's home: $219,425.49\n",
      "Predicted selling price for Client 3's home: $843,322.77\n",
      "Model has a coefficient of determination, R^2, of 0.847.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "client_data = [[5, 17, 15], # Client 1\n",
    "               [4, 32, 22], # Client 2\n",
    "               [8, 3, 12]]  # Client 3\n",
    "\n",
    "# Show predictions\n",
    "for i, price in enumerate(model.predict(client_data)):\n",
    "    print(\"Predicted selling price for Client {}'s home: ${:,.2f}\".format(i+1, price))\n",
    "    \n",
    "    \n",
    "# Calculate the performance of this model\n",
    "score = performance_metric(y_test, model.predict(X_test))\n",
    "print(\"Model has a coefficient of determination, R^2, of {:.3f}.\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
